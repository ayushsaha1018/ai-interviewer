import Groq from "groq-sdk";
import { headers } from "next/headers";
import { z } from "zod";
import { zfd } from "zod-form-data";
import { unstable_after as after } from "next/server";

const groq = new Groq();

const schema = zfd.formData({
  input: z.union([zfd.text(), zfd.file()]),
  message: zfd.repeatableOfType(
    zfd.json(
      z.object({
        role: z.enum(["user", "assistant"]),
        content: z.string(),
      })
    )
  ),
  jobRole: zfd.text(),
  jobDesc: zfd.text(),
  resumeContent: zfd.text(),
});

export async function POST(request: Request) {
  console.time("transcribe " + request.headers.get("x-vercel-id") || "local");

  const { data, success } = schema.safeParse(await request.formData());
  if (!success) return new Response("Invalid request", { status: 400 });

  const transcript = await getTranscript(data.input);
  if (!transcript) return new Response("Invalid audio", { status: 400 });

  console.timeEnd(
    "transcribe " + request.headers.get("x-vercel-id") || "local"
  );
  console.time(
    "text completion " + request.headers.get("x-vercel-id") || "local"
  );

  const completion = await groq.chat.completions.create({
    model: "llama3-8b-8192",
    messages: [
      {
        role: "system",
        content: `
			- You are Swift, an intelligent AI recruiter conducting an interview for the user.
			- The user is interviewing for the role of "${data.jobRole}".
			- The job description is: "${data.jobDesc}".
			- The user's resume is as follows: "${data.resumeContent}".
		  
			**Interview Guidelines:**
		  
			1. **Questioning:**
			   - Start by introducing yourself and the purpose of the interview in exactly 15 words.
			   - After the introduction, ask the first question. This question must be directly related to the job description and the user's resume. Avoid general or open-ended questions.
			   - When the user responds to the first question, acknowledge their answer briefly (e.g., "Understood your response"). Then, immediately proceed to ask the second question.
			   - The second question should also be job-specific and follow logically from the job description or resume.
			   - The questions should not be more than 15 words long.
		  
			2. **Evaluation and Feedback:**
			   - After the user responds to the second question, evaluate both responses together.
			   - Highlight one key strength and one area for improvement.
			   - Provide one suggestion for improvement.
			   - Do not exceed or elaborate beyond 30 words for feedback.
			   - Do not ask any new questions, just give the feedback.
			   - At last say this interview is ended and ask if the user has anymore questions
		  
			3. **Response Style:**
			   - Keep responses clear, concise, and professional.
			   - Avoid complex language or unnecessary details.
			   - Structure responses for easy text-to-speech clarity.
			   - Keep the response brief.
			   - Do not use special characters such as asterisks or any formatting (e.g., bold, italics).
			`,
      },
      ...data.message,
      {
        role: "user",
        content: transcript,
      },
    ],
  });

  const response = completion.choices[0].message.content;
  console.timeEnd(
    "text completion " + request.headers.get("x-vercel-id") || "local"
  );

  console.time(
    "cartesia request " + request.headers.get("x-vercel-id") || "local"
  );

  const voice = await fetch("https://api.cartesia.ai/tts/bytes", {
    method: "POST",
    headers: {
      "Cartesia-Version": "2024-06-30",
      "Content-Type": "application/json",
      "X-API-Key": process.env.CARTESIA_API_KEY!,
    },
    body: JSON.stringify({
      model_id: "sonic-english",
      transcript: response,
      voice: {
        mode: "id",
        id: "79a125e8-cd45-4c13-8a67-188112f4dd22",
      },
      output_format: {
        container: "raw",
        encoding: "pcm_f32le",
        sample_rate: 24000,
      },
    }),
  });

  console.timeEnd(
    "cartesia request " + request.headers.get("x-vercel-id") || "local"
  );

  if (!voice.ok) {
    console.error(await voice.text());
    return new Response("Voice synthesis failed", { status: 500 });
  }

  console.time("stream " + request.headers.get("x-vercel-id") || "local");
  after(() => {
    console.timeEnd("stream " + request.headers.get("x-vercel-id") || "local");
  });

  return new Response(voice.body, {
    headers: {
      "X-Transcript": encodeURIComponent(transcript),
      "X-Response": encodeURIComponent(response),
    },
  });
}

function location() {
  const headersList = headers();

  const country = headersList.get("x-vercel-ip-country");
  const region = headersList.get("x-vercel-ip-country-region");
  const city = headersList.get("x-vercel-ip-city");

  if (!country || !region || !city) return "unknown";

  return `${city}, ${region}, ${country}`;
}

function time() {
  return new Date().toLocaleString("en-US", {
    timeZone: headers().get("x-vercel-ip-timezone") || undefined,
  });
}

async function getTranscript(input: string | File) {
  if (typeof input === "string") return input;

  try {
    const { text } = await groq.audio.transcriptions.create({
      file: input,
      model: "whisper-large-v3",
    });

    return text.trim() || null;
  } catch {
    return null; // Empty audio file
  }
}
